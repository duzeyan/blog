#第一篇论文的摘要
本文中将会提出一个基于3维surfacelet变换（3D-ST）的视频融合框架。不同于传统的基于独立帧的视频融合方案，文中提出的会利用3D-ST把多帧图作为一个整体的输入量作为算法的输入。此外，在这个融合框架下，两种融合算法将会被提出来。第一种算法会无区别对待视频的帧内几何信息和时间上的连续信息，仅仅是计算时空域上能量来进行融合。相比之下，第二种融合算法会使用修正的Z-score来检测视频中的运动信息，从而把视频中静态的纹理信息和运动信息区分开来，再进一步进行融合。
实现显示，使用运动检测的融合方式可以在ST域下把背景和运动物体有效区分开来。上面提到的两种算法不论是细节上的提取还是时间上的连续性和稳定性都会明显优于传统的独立帧融合算法。

#第二篇论文的摘要
随着传感器技术的发展，各式各样的视频传感器被应用于监视系统，以期提高容错性和表现能力。并且，对同一场景使用不同的视频传感器会得到互相补充的视频信息内容。因此，如何有效组织利用这些同一场景不同传感器得到的内容引起了人们的兴趣。人们可以利用视频融合技术把这些独立的视频融合到一个混合视频中，该视频涵盖了多传感器的融合信息。